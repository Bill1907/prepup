# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Common Commands

```bash
# Development
npm run dev              # Start dev server with Turbopack
npm run build            # Build for production
npm run lint             # Run ESLint

# Cloudflare Deployment
npm run deploy           # Build and deploy to Cloudflare Workers
npm run preview          # Preview Cloudflare build locally
npm run cf-typegen       # Generate Cloudflare environment types

# Hasura (Local GraphQL)
docker-compose --env-file .env.local up -d   # Start Hasura with Neon connection
docker-compose down                           # Stop Hasura
# Console: http://localhost:8080 (Admin Secret: HASURA_ADMIN_SECRET)
```

## Architecture Overview

### Platform
Next.js 16 App Router deployed on Cloudflare Workers via OpenNext. Uses Neon PostgreSQL for database, Hasura for GraphQL API, and Cloudflare R2 for file storage.

### Authentication & Protected Routes
Clerk handles auth. The middleware at [middleware.ts](middleware.ts) protects all `/service/*` routes.

### Database Layer
- **Neon PostgreSQL**: Primary database (production branch: `br-flat-fog-a1tpbpze`)
- **Hasura GraphQL**: Local GraphQL engine connected to Neon (http://localhost:8080)
- **Tables**: users, resumes, resume_history, interview_questions, mock_interview_sessions, interview_answers, subscriptions, user_notes, usage_stats

### Data Fetching Layer
Client-side data fetching with GraphQL + TanStack Query:
- **GraphQL Client**: `lib/graphql/client.ts` - graphql-request client for Hasura
- **Queries/Mutations**: `lib/graphql/queries/` - GraphQL operations for resumes, questions
- **Custom Hooks**: `hooks/` - TanStack Query hooks with optimistic updates
  - `useResumes()`, `useResume(id)`, `useResumeStats()`, `useDeleteResume()`
  - `useQuestions()`, `useQuestionStats()`, `useToggleBookmark()`, `useDeleteQuestion()`

### Server Actions (`app/actions/`)
Server Actions for complex mutations (AI operations). Uses `auth()` from Clerk. Example: `analyzeResume()` uses OpenAI Assistants API with file upload.

### API Routes (`app/api/`)
REST endpoints for file operations:
- `/api/resumes/*` - Resume CRUD, file upload/download, presigned URLs
- `/api/files/*` - Generic file serving and presigned URL generation
- `/api/webhooks/clerk` - Clerk webhook for user sync

### File Storage Pattern
Files (resumes) are uploaded to R2 with keys like `resumes/{clerkUserId}/{resumeId}/{filename}`. Access is via presigned URLs generated through AWS4Fetch signing.

### UI Components
shadcn/ui with Radix primitives in `components/ui/`. Uses Tailwind CSS 4.

## Key Bindings

### Cloudflare (wrangler.jsonc)
- `prepup_files`: R2 bucket for file storage
- `AI`: Cloudflare AI binding

### Neon PostgreSQL
- Project: `prepup` (`lingering-wildflower-84781300`)
- Branch: `production` (`br-flat-fog-a1tpbpze`)
- Database: `neondb`

## Environment Variables
Required in `.env.local`:
- `CLERK_SECRET_KEY`, `NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY`, `CLERK_WEBHOOK_SECRET`
- `R2_ACCESS_KEY_ID`, `R2_SECRET_ACCESS_KEY`, `R2_ACCOUNT_ID` (for presigned URLs)
- `OPENAI_API_KEY` (for resume analysis)
- `NEON_DATABASE_URL` (PostgreSQL connection string)
- `HASURA_ADMIN_SECRET` (Hasura admin access)
- `NEXT_PUBLIC_HASURA_ENDPOINT` (GraphQL endpoint, default: http://localhost:8080/v1/graphql)
- `NEXT_PUBLIC_HASURA_ADMIN_SECRET` (for client-side GraphQL requests)

## Type Definitions
- `lib/graphql/queries/` - GraphQL response types and input types
- `cloudflare-env.d.ts`: Cloudflare environment bindings (auto-generated by `npm run cf-typegen`)
